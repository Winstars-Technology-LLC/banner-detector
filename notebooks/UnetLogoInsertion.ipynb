{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import yaml\n",
    "from BannerReplacer import BannerReplacer\n",
    "\n",
    "\n",
    "class UnetLogoInsertion(BannerReplacer):\n",
    "    '''\n",
    "    The model detects banner and replace it with other logo using Unet neural network model\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.detected_mask = None\n",
    "        self.detection_successful = False\n",
    "        self.frame = None\n",
    "        self.old_frame_gray = None\n",
    "        self.old_points = None\n",
    "        self.model_parameters = None\n",
    "        self.corners = None\n",
    "        self.first_frame = True\n",
    "        self.old_width = None\n",
    "        self.old_width_2 = None\n",
    "        \n",
    "    \n",
    "    def build_model(self, parameters_filepath):\n",
    "        '''\n",
    "        This method builds Unet neural network model and load trained weights\n",
    "        :parameters_filepath: load model parameters from YAML file\n",
    "        '''\n",
    "        # loading and saving model parameters to class attribute\n",
    "        with open(parameters_filepath, 'r') as file:\n",
    "            self.model_parameters = yaml.safe_load(file)\n",
    "        \n",
    "        # load parameters\n",
    "        img_height = self.model_parameters['img_height']\n",
    "        img_width = self.model_parameters['img_width']\n",
    "        img_channels = self.model_parameters['img_channels']\n",
    "        model_weights_path = self.model_parameters['model_weights_path']\n",
    "        train_model = self.model_parameters['train_model'] \n",
    "        \n",
    "        inputs = tf.keras.layers.Input((img_height, img_width, img_channels))\n",
    "\n",
    "        # CONTRACTION PATH\n",
    "        c1 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "        c1 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "        p1 = tf.keras.layers.MaxPooling2D((2,2))(c1)\n",
    "        p1 = tf.keras.layers.Dropout(0.2)(p1)\n",
    "\n",
    "        c2 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "        c2 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "        p2 = tf.keras.layers.MaxPooling2D((2,2))(c2)\n",
    "        p2 = tf.keras.layers.Dropout(0.2)(p2)\n",
    "\n",
    "        c3 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "        c3 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "        p3 = tf.keras.layers.MaxPooling2D((2,2))(c3)\n",
    "        p3 = tf.keras.layers.Dropout(0.2)(p3)\n",
    "\n",
    "        c4 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "        c4 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "        p4 = tf.keras.layers.MaxPooling2D((2,2))(c4)\n",
    "        p4 = tf.keras.layers.Dropout(0.2)(p4)\n",
    "\n",
    "        c5 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "        c5 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "        # EXPANSIVE PATH\n",
    "        u6 = tf.keras.layers.Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c5)\n",
    "        u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "        u6 = tf.keras.layers.Dropout(0.2)(u6)\n",
    "        c6 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "        c6 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "        u7 = tf.keras.layers.Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c6)\n",
    "        u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "        u7 = tf.keras.layers.Dropout(0.2)(u7)\n",
    "        c7 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "        c7 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "        u8 = tf.keras.layers.Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(c7)\n",
    "        u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "        u8 = tf.keras.layers.Dropout(0.2)(u8)\n",
    "        c8 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "        c8 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "        u9 = tf.keras.layers.Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(c8)\n",
    "        u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "        u9 = tf.keras.layers.Dropout(0.2)(u9)\n",
    "        c9 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "        c9 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "        outputs = tf.keras.layers.Conv2D(1, (1,1), activation='sigmoid')(c9)\n",
    "        self.model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "        self.model.compile(optimizer='adam', loss=self.__loss, metrics=[self.__dice_coef])\n",
    "        \n",
    "        # training model if required\n",
    "        if train_model:\n",
    "            x_train_path = self.model_parameters['x_train_path'] \n",
    "            y_train_path = self.model_parameters['y_train_path'] \n",
    "            self.__train_model(x_train_path, y_train_path, img_height, img_width, img_channels, model_weights_path)\n",
    "        \n",
    "        # load trained model weights\n",
    "        self.model.load_weights(model_weights_path)\n",
    "\n",
    "\n",
    "    def detect_banner(self, frame):\n",
    "        '''\n",
    "        This method detects banner's pixels using Unet model, and saves deteÑted binary mask\n",
    "        and saves coordinates for top left and bottom right corners of a banner\n",
    "        :frame: image or video frame where we will make detection and insertion\n",
    "        '''\n",
    "        self.frame = frame\n",
    "        \n",
    "        # load parameters\n",
    "        value_threshold = self.model_parameters['value_threshold']\n",
    "        filter_area_size = self.model_parameters['filter_area_size']\n",
    "        \n",
    "        # getting full size predicted mask of the frame\n",
    "        fsz_mask = self.__predict_full_size()\n",
    "        fsz_mask = (fsz_mask > value_threshold).astype(np.uint8)\n",
    "        \n",
    "        # looking for contours\n",
    "        first_cnt = True\n",
    "        _, thresh = cv2.threshold(fsz_mask, value_threshold, 255, 0)\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        for cnt in contours:\n",
    "            if cv2.contourArea(cnt) > filter_area_size:\n",
    "                \n",
    "                # works for the first contour\n",
    "                if first_cnt:\n",
    "                    x_top_left = cnt[:,0,0].min() \n",
    "                    x_bot_right = cnt[:,0,0].max()\n",
    "                    y_top_left = cnt[:,0,1].min() \n",
    "                    y_bot_right = cnt[:,0,1].max()\n",
    "                    first_cnt = False\n",
    "                \n",
    "                # works with more than one contour, and replace coordinates with more relevant\n",
    "                else:\n",
    "                    new_x_top_left = cnt[:,0,0].min() \n",
    "                    if new_x_top_left < x_top_left:\n",
    "                        x_top_left = new_x_top_left\n",
    "\n",
    "                    new_x_bot_right = cnt[:,0,0].max()\n",
    "                    if new_x_bot_right > x_bot_right:\n",
    "                        x_bot_right = new_x_bot_right\n",
    "\n",
    "                    new_y_top_left = cnt[:,0,1].min() \n",
    "                    if new_y_top_left < y_top_left:\n",
    "                        y_top_left = new_y_top_left \n",
    "\n",
    "                    new_y_bot_right = cnt[:,0,1].max()\n",
    "                    if new_y_bot_right > y_bot_right:\n",
    "                        y_bot_right = new_y_bot_right\n",
    "                \n",
    "                cv2.drawContours(fsz_mask, [cnt], -1, (1), -1)\n",
    "               \n",
    "        # save detected mask as a class attribute\n",
    "        self.detected_mask = fsz_mask\n",
    "        \n",
    "        if first_cnt:\n",
    "            return\n",
    "        \n",
    "        # save corners coordinates to class attribute\n",
    "        self.corners = [(x_top_left, y_top_left), (x_bot_right, y_bot_right)]\n",
    "        \n",
    "        # improving coordinate using optical flow \n",
    "        self.__check_optical_flow()\n",
    "        self.old_points = np.array([self.corners[0]], dtype=np.float32)\n",
    "        \n",
    "        # set that the banner detection was successful\n",
    "        self.detection_successful = True\n",
    "        \n",
    "    \n",
    "    def insert_logo(self):\n",
    "        '''\n",
    "        This method insert logo into detected area on the frame\n",
    "        '''\n",
    "        if not self.detection_successful:\n",
    "            return\n",
    "        \n",
    "        # load parameters\n",
    "        logo = cv2.imread(self.model_parameters['logo_link'], cv2.IMREAD_UNCHANGED)\n",
    "        height_coef = self.model_parameters['height_coef'] \n",
    "        width_coef = self.model_parameters['width_coef']\n",
    "        \n",
    "        x_top_left = self.corners[0][0]\n",
    "        y_top_left = self.corners[0][1]\n",
    "        x_bot_right = self.corners[1][0]\n",
    "        y_bot_right = self.corners[1][1]\n",
    "                                  \n",
    "        \n",
    "        # banner height before transformation\n",
    "        rect_height = y_bot_right - y_top_left\n",
    "        \n",
    "        # banner side height after transformation\n",
    "        height = rect_height*height_coef\n",
    "        \n",
    "        # banner width\n",
    "        width = (int(math.ceil((rect_height*width_coef)/10.0))*10)\n",
    "        \n",
    "        # keep same width if the changes was on only one frame\n",
    "        width = self.__adjust_logo_width(width)\n",
    "        \n",
    "        # adjust logo to banner's shape\n",
    "        transformed_logo = self.__adjust_logo_shape(logo, rect_height, height, width)\n",
    "        \n",
    "        # check the end of the banner on the frame\n",
    "        check_end_frame = lambda start, end, length: start+end if (start+end <= length) else length\n",
    "        end_y = check_end_frame(y_top_left, rect_height, self.frame.shape[0])\n",
    "        end_x = check_end_frame(x_top_left, width, self.frame.shape[1])\n",
    "        \n",
    "        # adjust logo color to the banner area\n",
    "        frame_cr = self.frame[y_top_left:end_y, x_top_left:end_x].copy()\n",
    "        transformed_logo = self.__logo_color_adj(transformed_logo, frame_cr)\n",
    "        \n",
    "        # replacing banner pixels with logo pixels\n",
    "        for k in range(y_top_left, end_y):\n",
    "            for j in range(x_top_left, end_x):\n",
    "                if self.detected_mask[k,j] == 1:\n",
    "                    self.frame[k,j] = transformed_logo[k-y_top_left,j-x_top_left]\n",
    "\n",
    "      \n",
    "    \n",
    "    \n",
    "    def __train_model(self, x_train_path, y_train_path, img_height, img_width, img_channels, model_weights_path):\n",
    "        '''\n",
    "        This method trains new model using X and Y train datasets\n",
    "        :x_train_path: the path to X train dataset\n",
    "        :y_train_path: the path to Y train dataset in .npy format\n",
    "        :img_height: train image height\n",
    "        :img_width: train image width\n",
    "        :img_channels: number of channels for train image \n",
    "        :model_weights_path: model weight path for saving\n",
    "        '''\n",
    "        # looking for files\n",
    "        train_x_list = next(os.walk(x_train_path))[2]\n",
    "        \n",
    "        # empty lists for X_traind and Y_train\n",
    "        x_train = np.zeros((len(train_x_list), img_height, img_width, img_channels), dtype=np.float32)\n",
    "        y_train = np.zeros((len(train_x_list), img_height, img_width, 1), dtype=np.float32)\n",
    "        \n",
    "        # replacing empty lists elements with actual train data\n",
    "        n = 0\n",
    "        for file in train_x_list:\n",
    "            x_train_file = x_train_path + file\n",
    "            id_, _ = file.split('.')\n",
    "            y_train_file = y_train_path + id_ + '.npy'\n",
    "            x = cv2.imread(x_train_file, cv2.IMREAD_UNCHANGED)\n",
    "            y = np.load(y_train_file)\n",
    "            y_ = np.expand_dims(y, axis=-1)\n",
    "            x_train[n] = x\n",
    "            y_train[n] = y_\n",
    "            n += 1\n",
    "        \n",
    "        # setting callbacks for the model\n",
    "        callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "                    tf.keras.callbacks.ModelCheckpoint(model_weights_path, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True)]\n",
    "        \n",
    "        # training the model\n",
    "        self.model.fit(x_train, y_train, validation_split=0.1, epochs=200, callbacks=callbacks)\n",
    "        \n",
    "        \n",
    "\n",
    "    def __loss(self, y_true, y_pred):\n",
    "        '''\n",
    "        Creating combined BCE and Dice Loss function which we will use in the model\n",
    "        :y_true: actual Y values of test data\n",
    "        :y_pred: predicted Y values of test data\n",
    "        :return: combined BCE and Dice Loss function \n",
    "        '''\n",
    "        return tf.keras.losses.binary_crossentropy(y_true, y_pred) + self.__dice_loss(y_true, y_pred)\n",
    "    \n",
    "\n",
    "    \n",
    "    def __dice_loss(self, y_true, y_pred):\n",
    "        '''\n",
    "        Creating a Dice Loss function for our model\n",
    "        :y_true: actual Y values of test data\n",
    "        :y_pred: predicted Y values of test data\n",
    "        :return: Dice Loss function\n",
    "        '''\n",
    "        numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=(1, 2, 3))\n",
    "        denominator = tf.reduce_sum(y_true + y_pred, axis=(1, 2, 3))\n",
    "        return tf.reshape(1 - numerator / denominator, (-1, 1, 1))\n",
    "    \n",
    "\n",
    "\n",
    "    def __dice_coef(self, y_true, y_pred):\n",
    "        '''\n",
    "        Creating a Dice Coefficient to use it like a metric in our model\n",
    "        :y_true: actual Y values of test data\n",
    "        :y_pred: predicted Y values of test data\n",
    "        :return: Dice Coefficient \n",
    "        '''\n",
    "        numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=-1)\n",
    "        denominator = tf.reduce_sum(y_true + y_pred, axis=-1)\n",
    "        return (numerator + 1) / (denominator + 1)\n",
    "    \n",
    "    \n",
    "    def __check_optical_flow(self):\n",
    "        '''\n",
    "        Works for video, predicts where the previous point is supposed to be \n",
    "        on the next frame\n",
    "        :return: the point that was predicted and the GRAY frame which need to be used for the next frame\n",
    "        '''\n",
    "        gray_frame = cv2.cvtColor(self.frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # load parameters\n",
    "        diff = self.model_parameters['diff']\n",
    "        winSize = self.model_parameters['winSize']\n",
    "        maxLevel = self.model_parameters['maxLevel']\n",
    "        \n",
    "        lk_params = dict(winSize = (winSize, winSize), \n",
    "                         maxLevel = maxLevel, \n",
    "                         criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "        \n",
    "        if self.first_frame:\n",
    "            self.old_frame_gray = gray_frame.copy()\n",
    "            self.first_frame = False\n",
    "            return\n",
    "        \n",
    "        new_points_flow, status, error = cv2.calcOpticalFlowPyrLK(self.old_frame_gray, gray_frame, self.old_points, None, **lk_params)\n",
    "        new_x, new_y = new_points_flow.ravel()\n",
    "\n",
    "        self.old_frame_gray = gray_frame.copy()\n",
    "        if abs(self.corners[0][0]-new_x) < diff and abs(self.corners[0][1]-new_y) < diff:\n",
    "                self.corners[0] = int(round(new_x)), int(round(new_y))\n",
    "                \n",
    "    \n",
    "    def __adjust_logo_width(self, width):\n",
    "        '''\n",
    "        The method dellays width changing, and if the change was only for one frame\n",
    "        and then returned back, it keeps same width without changing\n",
    "        :return: adjusted width \n",
    "        '''\n",
    "        temp_width = width\n",
    "        \n",
    "        if width != self.old_width and width != self.old_width_2 and self.old_width != None:\n",
    "            temp_width = self.old_width  \n",
    "\n",
    "        self.old_width_2 = self.old_width   \n",
    "        self.old_width = width       \n",
    "        width = temp_width\n",
    "        return width\n",
    "    \n",
    "    \n",
    "    def __adjust_logo_shape(self, logo, rect_height, height, width):\n",
    "        '''\n",
    "        The method resizes and applies perspective transformation on logo\n",
    "        :logo: the logo that we will transform\n",
    "        :rect_height: height of the rectangular logo before transformation\n",
    "        :height: height of the logo after transformation\n",
    "        :width: width of the logo\n",
    "        :return: transformed logo\n",
    "        '''\n",
    "        # resize the logo\n",
    "        resized_logo = cv2.resize(logo, (width, rect_height))\n",
    "        \n",
    "        # transform the logo\n",
    "        pts1 = np.float32([(0, 0), (0, rect_height), (width, rect_height), (width, 0)])\n",
    "        pts2 = np.float32([(0, 0), (0, height), (width, rect_height), (width, rect_height-height)]) \n",
    "        mtrx = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "        transformed_logo = cv2.warpPerspective(resized_logo, mtrx, (width, rect_height), borderMode=1)\n",
    "        return transformed_logo\n",
    "    \n",
    "   \n",
    "    def __logo_color_adj(self, logo, banner):\n",
    "        '''\n",
    "        The method changes color of the logo to adjust it to frame\n",
    "        :logo: the logo that we will change\n",
    "        :banner: area of detected banner\n",
    "        :return: changed logo\n",
    "        '''\n",
    "        # get logo hsv\n",
    "        logo_hsv = cv2.cvtColor(logo, cv2.COLOR_BGR2HSV)\n",
    "        logo_h, logo_s, logo_v = cv2.split(logo_hsv)\n",
    "        \n",
    "        # get banner hsv\n",
    "        banner_hsv = cv2.cvtColor(banner, cv2.COLOR_BGR2HSV)\n",
    "        _, banner_s, _ = cv2.split(banner_hsv)\n",
    "\n",
    "        # find the saturation difference between both images\n",
    "        mean_logo_s = np.mean(logo_s).astype(int)\n",
    "        mean_banner_s = np.mean(banner_s).astype(int)\n",
    "        trans_coef = round(mean_banner_s/mean_logo_s, 2)    \n",
    "        \n",
    "        # adjust logo saturation according to the difference\n",
    "        adjusted_logo_s = (logo_s*trans_coef).astype('uint8')\n",
    "        adjusted_logo_hsv = cv2.merge([logo_h, adjusted_logo_s, logo_v])\n",
    "        adjusted_logo = cv2.cvtColor(adjusted_logo_hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "        return adjusted_logo\n",
    "\n",
    "    def __predict_full_size(self):\n",
    "        '''\n",
    "        The method goes trougth the frame and detects smaller areas,\n",
    "        then combines them togeather\n",
    "        :return: full size mask with detected banner pixels\n",
    "        '''\n",
    "        # load parameters\n",
    "        img_height = self.model_parameters['img_height']\n",
    "        img_width = self.model_parameters['img_width']\n",
    "        step = self.model_parameters['full_size_step']\n",
    "        \n",
    "        # getting the frame size\n",
    "        frame_height, frame_width, _ = self.frame.shape\n",
    "        \n",
    "        # create mask for full size image prediction\n",
    "        fsz_mask = np.zeros((frame_height, frame_width, 1), dtype='float32')\n",
    "\n",
    "        flag_k = False\n",
    "        flag_j = False\n",
    "        \n",
    "        # split up the full frame to smaller images (same than using in model) and predict them\n",
    "        for k in range(0, frame_height, step):\n",
    "            if k + img_height >= (frame_height-1):\n",
    "                k = frame_height - img_height\n",
    "                flag_k = True\n",
    "\n",
    "            for j in range(0, frame_width, step):\n",
    "                if j + img_width >= (frame_width-1):\n",
    "                    j = frame_width - img_width\n",
    "                    flag_j = True\n",
    "                    \n",
    "                mask_cr = fsz_mask[k:k + img_height, j:j + img_width]\n",
    "                frame_cr = self.frame[k:k + img_height, j:j + img_width]\n",
    "                test_cr = np.expand_dims(frame_cr, axis=0)\n",
    "                cr_predict = self.model.predict(test_cr)\n",
    "            \n",
    "                for y in range(img_height):\n",
    "                    for x in range(img_width):\n",
    "                        if cr_predict[0][y, x] > mask_cr[y, x]:\n",
    "                            mask_cr[y, x] = cr_predict[0][y, x]\n",
    "\n",
    "                if flag_j:\n",
    "                    break\n",
    "\n",
    "            if flag_k:\n",
    "                break\n",
    "     \n",
    "        return fsz_mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    logo_insertor = UnetLogoInsertion()\n",
    "    logo_insertor.build_model('model_parameters_setting')\n",
    "    \n",
    "    # load parameters\n",
    "    source_type = logo_insertor.model_parameters['source_type']\n",
    "    source_link = logo_insertor.model_parameters['source_link']\n",
    "    save_result = logo_insertor.model_parameters['save_result']\n",
    "    saving_link = logo_insertor.model_parameters['saving_link']\n",
    "    \n",
    "    # works with video\n",
    "    if source_type == 0:\n",
    "        cap = cv2.VideoCapture(source_link)\n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height = int(cap.get(4))\n",
    "        four_cc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "        out = cv2.VideoWriter(saving_link, four_cc, 30, (frame_width, frame_height), True)\n",
    "        \n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if ret:\n",
    "                logo_insertor.detect_banner(frame)\n",
    "                logo_insertor.insert_logo()\n",
    "                \n",
    "                if save_result:\n",
    "                    out.write(frame)\n",
    "                    \n",
    "                cv2.imshow('Video (press Q to close)', frame)\n",
    "                if cv2.waitKey(23) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        out.release()\n",
    "    \n",
    "    # works with image\n",
    "    else:\n",
    "        frame = cv2.imread(source_link, cv2.IMREAD_UNCHANGED)\n",
    "        logo_insertor.detect_banner(frame)\n",
    "        logo_insertor.insert_logo()\n",
    "        if save_result:\n",
    "            cv2.imwrite(saving_link, frame)\n",
    "        cv2.imshow('Image (press Q to close)', frame)\n",
    "        if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
